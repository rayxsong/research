# Negation Bechmark
- Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation, [paper](https://arxiv.org/pdf/2210.03256.pdf), [repo](https://github.com/tsafavi/NegatER)
- Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge, [paper](https://arxiv.org/pdf/2305.05976.pdf)
- Language models are not naysayers: An analysis of language models on negation benchmarks, [paper](https://arxiv.org/pdf/2306.08189.pdf), [repo](https://github.com/joey234/llm-neg-bench)

# Negation Dataset
- UnCommonSense: Informative Negative Knowledge about Everyday Concepts, [paper](https://dl.acm.org/doi/10.1145/3511808.3557484), [dataset](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/commonsense/uncommonsense)
- This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models, [paper](https://arxiv.org/pdf/2310.15941.pdf), [dataset](https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset?row=1)
- “I’m Not Mad”: Commonsense Implications of Negation and Contradiction, [paper](https://aclanthology.org/2021.naacl-main.346.pdf), [ANION dataset](https://github.com/liweijiang/anion?tab=readme-ov-file)
# Other
- Negated Complementary Commonsense using Large Language Models, [paper](https://arxiv.org/pdf/2307.06794.pdf), [repo](https://github.com/navidre/negated_complementary_commonsense)